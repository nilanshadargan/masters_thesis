{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e25ea09-74d6-47e6-bad6-e922f52c3532",
   "metadata": {
    "id": "5e25ea09-74d6-47e6-bad6-e922f52c3532"
   },
   "source": [
    "# Personal Information\n",
    "Name: **Nilansha Dargan**\n",
    "\n",
    "StudentID: **13130366**\n",
    "\n",
    "Email: [**nilansha.dargan@student.uva.nl**](nilansha.dargan@student.uva.nl)\n",
    "\n",
    "Submitted on: **22.03.2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf6243-adfe-4eb8-bba3-bb2835079abd",
   "metadata": {
    "id": "e3cf6243-adfe-4eb8-bba3-bb2835079abd"
   },
   "source": [
    "# Data Context\n",
    "**Our research focuses on exploring the feasibility of classifying startup companies across multiple dimensions for investment purposes, specifically in a zero-shot context. This investigation is particularly relevant for our use case: Azimut Zero, a Due Diligence Startup specializing in evaluating deep tech startups for investment viability. The majority of this notebook will involve performing exploratory data analysis on data samples, that are AI start-ups' information, provided by the company.  These samples comprise two main types of textual data: PDF files of slide decks and Excel spreadsheets containing questionnaire responses. Often these samples also have a word document. Our analysis will delve into two samples  this textual data.**\n",
    "\n",
    "**Along with that, we are developing an evaluation dataset based on the Y Combinator Directory, available on Kaggle (link: [Y Combinator Directory](https://www.kaggle.com/datasets/miguelcorraljr/y-combinator-directory?select=2023-07-13-yc-companies.csv)). It will be made by scarping the homepages of the company websites and classifying them in three dimension. As this dataset is currently under construction, only preliminary EDA has been conducted on it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833d964-56e1-49c7-8172-7435357624aa",
   "metadata": {
    "id": "a833d964-56e1-49c7-8172-7435357624aa"
   },
   "source": [
    "# Data Description\n",
    "\n",
    "**As mentioned before the type of data in question for the reseach is texual data. In this data, three experiments were analysed.**\n",
    "\n",
    "***Analysis 1: Word Count Analysis***\n",
    "\n",
    "**The initial experiment focused on quantifying the total number of words present in each data sample. Analysis of the first data sample revealed a word count of 4,386, whereas the second sample contained 6,638 words. These findings suggest a typical range of 4,000 to 7,000 words for similar data samples. The self-generated dataset from YC will a lower word count.**\n",
    "\n",
    "\n",
    "***Analysis 2: Word Frequency Analysis***\n",
    "\n",
    "**The second experiment aimed to identify the 10 most frequently occurring words within each data sample, under two conditions: with and without the removal of stopwords. The findings are as follows:**\n",
    "\n",
    "**Data Sample 1:**\n",
    "\n",
    "**With stopwords: [('the', 216), ('of', 147), ('and', 106), ('our', 88), ('to', 88), ('a', 76), ('is', 60), ('in', 60), ('for', 58), ('we', 57)]**\n",
    "**Without stopwords: [('data', 54), ('machine', 43), ('model', 35), ('company', 26), ('ai', 26), ('maintenance', 23), ('training', 21), ('system', 20), ('models', 17), ('process', 16)]**\n",
    "\n",
    "\n",
    "**Data Sample 2:**\n",
    "\n",
    "**With stopwords: [('the', 340), ('to', 179), ('and', 158), ('of', 143), ('is', 136), ('our', 117), ('a', 110), ('in', 100), ('for', 100), ('we', 92)]**\n",
    "**Without stopwords: [('data', 48), ('models', 47), ('product', 41), ('new', 38), ('detection', 33), ('company', 32), ('per', 31), ('security', 27), ('streams', 25), ('model', 22)]**\n",
    "**This experiment showed the dominance of stopwords in the datasets when they are not removed.**\n",
    "\n",
    "***Analysis 3: Cosine Similarity Analysis***\n",
    "\n",
    "**The third analytical phase incorporated a cosine similarity computation. This involved measuring the semantic similarity between the combined text from all data sources for a sample and a set of predefined dimensions relevant to the research. Building on insights from the previous experiment, the scores were also checked on text where stopwords were removed. The results indicated a notable increase in similarity scores across different dimensions, providing a crucial insight into the significance of this data cleaning step in this research.**\n",
    "\n",
    "***Preliminary Dataset Formation Analysis***\n",
    "\n",
    "**The last analysis of the first steps towards developing a dataset from the Y Combinator (YC) directory. From a pool of 8,411  startup companies, it was determined that approximately 599 companies specialize in Artificial Intelligence (AI).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nnj00Zfg6v0l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnj00Zfg6v0l",
    "outputId": "b12d98d9-5b27-4838-d443-26abf289f8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Obtaining dependency information for python-docx from https://files.pythonhosted.org/packages/5f/d8/6948f7ac00edf74bfa52b3c5e3073df20284bec1db466d13e668fe991707/python_docx-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting PyPDF2\n",
      "  Obtaining dependency information for PyPDF2 from https://files.pythonhosted.org/packages/8e/5e/c86a5643653825d3c913719e788e41386bee415c2b87b4f955432f2de6b2/pypdf2-3.0.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/nilanshadargan/anaconda3/lib/python3.11/site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/nilanshadargan/anaconda3/lib/python3.11/site-packages (from python-docx) (4.9.0)\n",
      "Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx, PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1 python-docx-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534317db-d881-4e33-a358-754e2881e8bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "534317db-d881-4e33-a358-754e2881e8bd",
    "outputId": "ba863e15-4565-4dde-d57c-da5d1ff86174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nilanshadargan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nilanshadargan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx\n",
    "import PyPDF2\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582b299-f599-4140-a454-bcbfdeeb273f",
   "metadata": {
    "id": "b582b299-f599-4140-a454-bcbfdeeb273f"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0cf9be-2cac-4227-957f-ad893212e70c",
   "metadata": {
    "id": "9f0cf9be-2cac-4227-957f-ad893212e70c"
   },
   "outputs": [],
   "source": [
    "data_1_pdf = 'Data/Data sample 1/ai deck.pdf'\n",
    "data_1_excel = 'Data/Data sample 1/data sample 1.xlsx'\n",
    "data_2_pdf = '/content/20240102_AzimutZer0_Slides.pdf'\n",
    "data_2_pdf_2 = '/content/Q10. Models Finetuning Process.pdf'\n",
    "data_2_pdf_3 = '/content/Q6. Quality Assurance overview.pdf'\n",
    "data_2_excel = '/content/data sample 2.xlsx'\n",
    "data_2_doc_1 = '/content/Q17. 20240102 Update to team_ch6.docx'\n",
    "data_2_doc_2 = '/content/Q27. Procedure Security Incidents.docx'\n",
    "ycd_data = '/content/2023-07-13-yc-companies.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df9546-a6d7-4678-aca6-cd13d5f3c79a",
   "metadata": {
    "id": "b4df9546-a6d7-4678-aca6-cd13d5f3c79a"
   },
   "source": [
    "###Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "LtAC0Mlo6b7Y",
   "metadata": {
    "id": "LtAC0Mlo6b7Y"
   },
   "outputs": [],
   "source": [
    "def read_excel_file(file_path, columns=None):\n",
    "    \"\"\"Reads specified columns from an Excel file.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_excel(file_path, usecols=columns)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return f\"Error reading {file_path}: {e}\"\n",
    "\n",
    "def read_word_file(file_path):\n",
    "    \"\"\"Reads data from a Word document.\"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        return '\\n'.join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        return f\"Error reading {file_path}: {e}\"\n",
    "\n",
    "def read_pdf_file(file_path):\n",
    "    \"\"\"Reads data from a PDF file using PyPDF2 version 3.0.0 or later.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = []\n",
    "            for page in pdf_reader.pages:\n",
    "                text.append(page.extract_text())\n",
    "            return '\\n'.join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error reading {file_path}: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "EY6ouIZqR_oA",
   "metadata": {
    "id": "EY6ouIZqR_oA"
   },
   "outputs": [],
   "source": [
    "#Data Sample 1\n",
    "data_1_pdf_data = read_pdf_file(data_1_pdf)\n",
    "data_1_excel_data = read_excel_file(data_1_excel)\n",
    "\n",
    "#Data Sample 2\n",
    "data_2_pdf_data = read_pdf_file(data_2_pdf)\n",
    "data_2_excel_data = read_excel_file(data_2_excel)\n",
    "data_2_pdf_2_data = read_pdf_file(data_2_pdf_2)\n",
    "data_2_pdf_3_data = read_pdf_file(data_2_pdf_3)\n",
    "data_2_doc_1_data = read_word_file(data_2_doc_1)\n",
    "data_2_doc_2_data = read_word_file(data_2_doc_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pPG5piVAW0jL",
   "metadata": {
    "id": "pPG5piVAW0jL"
   },
   "source": [
    "###Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B8ITITLGYa9u",
   "metadata": {
    "id": "B8ITITLGYa9u"
   },
   "source": [
    "Excels: Non useful columns Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bqeP9RkqYZks",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bqeP9RkqYZks",
    "outputId": "bc74bdda-175b-434f-a722-46cf3d1f6f70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Your answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the estimated TRL level of your product?</td>\n",
       "      <td>See https://ec.europa.eu/research/participants...</td>\n",
       "      <td>The current Technology Readiness Level (TRL) o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To what extent do you build your algorithms in...</td>\n",
       "      <td>I.e. fully built in-house vs. based on 3rd par...</td>\n",
       "      <td>Our models have been developed and assessed en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you give an overview of the relevant data ...</td>\n",
       "      <td>Describe your datasets and any issues/gaps it ...</td>\n",
       "      <td>We maintain an extensive library of recordings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you own the relevant data?</td>\n",
       "      <td>Why (not)? If you don't own it, who does?</td>\n",
       "      <td>We hold exclusive ownership of all data we hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you briefly describe your data processing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our machine learning (ML) approach for the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do you measure performance of your AI models?</td>\n",
       "      <td>Which metrics do you use and why are they adeq...</td>\n",
       "      <td>We have developed an advanced machine learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Can you briefly describe your (AI/ML) product ...</td>\n",
       "      <td>Concerning design choices and considerations, ...</td>\n",
       "      <td>We are having many brainstorming discussions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you briefly describe your IP generation &amp; ...</td>\n",
       "      <td>I.e. patents, scientific publications, FTO...</td>\n",
       "      <td>our company holds full ownership of its intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can you give an overview of the (AI/ML) techni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our team consists of four highly skilled indiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can you provide your technology and/or product...</td>\n",
       "      <td>Alternatively, point us to its place in the do...</td>\n",
       "      <td>Provided as part of the \"02 Technology Overvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Can you briefly describe your AI and/or data s...</td>\n",
       "      <td>Alternatively, point us to its place in the do...</td>\n",
       "      <td>Provided as part of the \"04 How Our AI Works 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are the challenging cases for your model(...</td>\n",
       "      <td>E.g. to account for the long tail? Do your ser...</td>\n",
       "      <td>Each model we develop is automatically fine-tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Can you briefly describe training new models a...</td>\n",
       "      <td>To what extent is it automatic vs. manual, wha...</td>\n",
       "      <td>When a customer adds an event label through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What about new use-cases?</td>\n",
       "      <td>I.e. what does it take to add new use-cases to...</td>\n",
       "      <td>Our system is designed with versatility in min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How and when does model re-training happen?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our models are retrained using the One-Click T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How unique do you estimate your AI product to ...</td>\n",
       "      <td>I.e. will it become obsolete in 2, 3, 5 years ...</td>\n",
       "      <td>The automatic training facilitated by our One-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Is explainability important in the application...</td>\n",
       "      <td>If so, how do you (plan to) achieve it?</td>\n",
       "      <td>The ability to diagnose specific issues within...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What about model bias/fairness, does it apply ...</td>\n",
       "      <td>If so, what mechanisms do you have in place &amp; ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Will you be subject to EU’s AI Act?</td>\n",
       "      <td>If so, what is your estimated risk level?</td>\n",
       "      <td>EU AI Act primarily focuses on the use and reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What measures do you take to account for data ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not process any individual personal data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(If applicable) Is there a risk of system down...</td>\n",
       "      <td>If so, what mechanisms do you have in place to...</td>\n",
       "      <td>Our typical solution functions primarily as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(If applicable) Do you need to integrate with ...</td>\n",
       "      <td>Are there standard protocols that you have to ...</td>\n",
       "      <td>While our standard approach does not typically...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0    What is the estimated TRL level of your product?   \n",
       "1   To what extent do you build your algorithms in...   \n",
       "2   Can you give an overview of the relevant data ...   \n",
       "3                       Do you own the relevant data?   \n",
       "4   Can you briefly describe your data processing ...   \n",
       "5   How do you measure performance of your AI models?   \n",
       "6   Can you briefly describe your (AI/ML) product ...   \n",
       "7   Can you briefly describe your IP generation & ...   \n",
       "8   Can you give an overview of the (AI/ML) techni...   \n",
       "9   Can you provide your technology and/or product...   \n",
       "10  Can you briefly describe your AI and/or data s...   \n",
       "11  What are the challenging cases for your model(...   \n",
       "12  Can you briefly describe training new models a...   \n",
       "13                          What about new use-cases?   \n",
       "14        How and when does model re-training happen?   \n",
       "15  How unique do you estimate your AI product to ...   \n",
       "16  Is explainability important in the application...   \n",
       "17  What about model bias/fairness, does it apply ...   \n",
       "18                Will you be subject to EU’s AI Act?   \n",
       "19  What measures do you take to account for data ...   \n",
       "20  (If applicable) Is there a risk of system down...   \n",
       "21  (If applicable) Do you need to integrate with ...   \n",
       "\n",
       "                                              Comment  \\\n",
       "0   See https://ec.europa.eu/research/participants...   \n",
       "1   I.e. fully built in-house vs. based on 3rd par...   \n",
       "2   Describe your datasets and any issues/gaps it ...   \n",
       "3           Why (not)? If you don't own it, who does?   \n",
       "4                                                 NaN   \n",
       "5   Which metrics do you use and why are they adeq...   \n",
       "6   Concerning design choices and considerations, ...   \n",
       "7       I.e. patents, scientific publications, FTO...   \n",
       "8                                                 NaN   \n",
       "9   Alternatively, point us to its place in the do...   \n",
       "10  Alternatively, point us to its place in the do...   \n",
       "11  E.g. to account for the long tail? Do your ser...   \n",
       "12  To what extent is it automatic vs. manual, wha...   \n",
       "13  I.e. what does it take to add new use-cases to...   \n",
       "14                                                NaN   \n",
       "15  I.e. will it become obsolete in 2, 3, 5 years ...   \n",
       "16            If so, how do you (plan to) achieve it?   \n",
       "17  If so, what mechanisms do you have in place & ...   \n",
       "18          If so, what is your estimated risk level?   \n",
       "19                                                NaN   \n",
       "20  If so, what mechanisms do you have in place to...   \n",
       "21  Are there standard protocols that you have to ...   \n",
       "\n",
       "                                          Your answer  \n",
       "0   The current Technology Readiness Level (TRL) o...  \n",
       "1   Our models have been developed and assessed en...  \n",
       "2   We maintain an extensive library of recordings...  \n",
       "3   We hold exclusive ownership of all data we hav...  \n",
       "4   Our machine learning (ML) approach for the pro...  \n",
       "5   We have developed an advanced machine learning...  \n",
       "6   We are having many brainstorming discussions, ...  \n",
       "7   our company holds full ownership of its intell...  \n",
       "8   Our team consists of four highly skilled indiv...  \n",
       "9   Provided as part of the \"02 Technology Overvie...  \n",
       "10  Provided as part of the \"04 How Our AI Works 2...  \n",
       "11  Each model we develop is automatically fine-tu...  \n",
       "12  When a customer adds an event label through ou...  \n",
       "13  Our system is designed with versatility in min...  \n",
       "14  Our models are retrained using the One-Click T...  \n",
       "15  The automatic training facilitated by our One-...  \n",
       "16  The ability to diagnose specific issues within...  \n",
       "17                                                NaN  \n",
       "18  EU AI Act primarily focuses on the use and reg...  \n",
       "19  We do not process any individual personal data...  \n",
       "20  Our typical solution functions primarily as a ...  \n",
       "21  While our standard approach does not typically...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_excel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "LfQ7eCfKjK8d",
   "metadata": {
    "id": "LfQ7eCfKjK8d"
   },
   "outputs": [],
   "source": [
    "data_1_excel_data.drop(['Question', 'Comment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "NqYrQRM4jZuy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "NqYrQRM4jZuy",
    "outputId": "e315d220-e74a-43c6-8829-2f15a704f8d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Your answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The current Technology Readiness Level (TRL) o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our models have been developed and assessed en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We maintain an extensive library of recordings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We hold exclusive ownership of all data we hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our machine learning (ML) approach for the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We have developed an advanced machine learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We are having many brainstorming discussions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>our company holds full ownership of its intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Our team consists of four highly skilled indiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Provided as part of the \"02 Technology Overvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Provided as part of the \"04 How Our AI Works 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Each model we develop is automatically fine-tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When a customer adds an event label through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Our system is designed with versatility in min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Our models are retrained using the One-Click T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The automatic training facilitated by our One-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The ability to diagnose specific issues within...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EU AI Act primarily focuses on the use and reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>We do not process any individual personal data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Our typical solution functions primarily as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>While our standard approach does not typically...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Your answer\n",
       "0   The current Technology Readiness Level (TRL) o...\n",
       "1   Our models have been developed and assessed en...\n",
       "2   We maintain an extensive library of recordings...\n",
       "3   We hold exclusive ownership of all data we hav...\n",
       "4   Our machine learning (ML) approach for the pro...\n",
       "5   We have developed an advanced machine learning...\n",
       "6   We are having many brainstorming discussions, ...\n",
       "7   our company holds full ownership of its intell...\n",
       "8   Our team consists of four highly skilled indiv...\n",
       "9   Provided as part of the \"02 Technology Overvie...\n",
       "10  Provided as part of the \"04 How Our AI Works 2...\n",
       "11  Each model we develop is automatically fine-tu...\n",
       "12  When a customer adds an event label through ou...\n",
       "13  Our system is designed with versatility in min...\n",
       "14  Our models are retrained using the One-Click T...\n",
       "15  The automatic training facilitated by our One-...\n",
       "16  The ability to diagnose specific issues within...\n",
       "17                                                NaN\n",
       "18  EU AI Act primarily focuses on the use and reg...\n",
       "19  We do not process any individual personal data...\n",
       "20  Our typical solution functions primarily as a ...\n",
       "21  While our standard approach does not typically..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_excel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zfCo-QUgjyw4",
   "metadata": {
    "id": "zfCo-QUgjyw4"
   },
   "outputs": [],
   "source": [
    "data_2_excel_data.drop(['Question', 'Comment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IyMkdc-dYd4L",
   "metadata": {
    "id": "IyMkdc-dYd4L"
   },
   "source": [
    "PDFs: Punctuation and '/n' Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qwz0rW_fWyML",
   "metadata": {
    "id": "Qwz0rW_fWyML"
   },
   "outputs": [],
   "source": [
    "def clean_text(input_text):\n",
    "    # Replace newline (\\n) characters with spaces\n",
    "    cleaned_text = input_text.replace('\\n', ' ')\n",
    "\n",
    "    # Remove punctuations\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A_9CE4fnWHWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "A_9CE4fnWHWA",
    "outputId": "e6952e27-12fe-423d-dbf4-21eecdd9e934"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Copyright Our company 23  All rights reserved  Confidential  1  The cutting Edge   Brainware    Copyright Our company 23  All rights reserved  Confidential   PF Curve  Predictive maintenance 40  Our company reshapes maintenance   Our company protects machines     Industry 40 will reshape the business and the economic  landscape over the next 10 15 years Use of IoT and AI reshapes  how the predictive maintenance is done     The typical level of maintenance maturity are defined as    Level 1 Manual visual inspections  The focus is on the  preventive time based maintenance or use of the run to  failure mode    Level 2 Regular instrument inspections  The key assets  are monitored The frequency is based on its severity    Level 3 Real time condition monitoring  The most of the  assets are monitoring remotely Manually  simple logic  data interpretation    Level 4 Predictive maintenance 40  It applies complex  algorithm to assess health condition of each machine The  results are used for the effective maintenance planning      Copyright Our company 23  All rights reserved  Confidential   Condition based maintenance  Predictive  Maintenance 40   Condition based maintenance was traditionally done only just on  high value assets With Predictive Maintenance 40 the combination  of AI and IoT improves predictability and increases the number of  machines where condition based maintenance make economical  sense     PWC study shows that the key expectations of investing into IoT  for PdM 40 by plant managers are   Keep risk of unplanned downtime low 51   Lower the maintenance and energy costs 11   Reducing risks associated with safety health environment and  quality SHEQ 8   Prolong the assets lifespan 7   Improving customer satisfaction 12    PWC Iot Study Available at  httpswwwstrategyandpwccomgxeninsightsindustry4 0html   Copyright Our company 23  All rights reserved  Confidential  Conditional based predictive maintenance savings    How do we deliver   A few examples presented here demonstrate of the impact of   A shut down of a power plant costs 12 millionGW per year   A manufacturing stop in the auto industry  19000min1   A single furnace energy savings equivalent of 1500 EUR per casting   900000 EUR per year   A disruption of a paper mill cost  210000 per year   A downtime for a packaging line costs 130min  The most issues are preventable   We have prevented some and recognized many coming failures  PWC IoT in PdM Study shows that about 30 40 of maintenance  costs are related to unnecessary expenditures due to bad planning  overtime of maintenance technicians and lack of preventive  maintenance   Reliability cost news to be balanced   The important factor is also cost of low reliability which is what the  most managers are looking for The optimal overall cost of operation  needs to consider both  reliability and maintenance cost Some  customers are looking for increasing reliability and others for  lowering the maintenance by optimising the personal and material  cost    Our Solution   We can identify about 70 90 of the issues depending on the type  of the machine before any other method Our nGuard platform  provides an enabler for Predictive maintenance savings Contact our  sales team to learn more about ROI     PWC Iot Study Available at  httpswwwstrategyandpwccomgxeninsightsindustry4 0html    Copyright Our company 23  All rights reserved  Confidential   Technology overview  Our company   Our company protects machines   The solution builds on traditional diagnostic methods and  mechanical knowledge of machines with unique power of AI   Unlike other predictive maintenance solutions Our company  delivers an online 247 continuous monitoring through IoT HW  solution and data processing at the installation site on edge Easy  installation makes it possible to launch the service within hours   The necessary certifications even for explosive environments  increase work safety and replace human labor where it is not  necessarily needed     Top AI Solution   The company AI team is ranked in the worlds Top 5 among  solutions for anomaly detection on machinery using artificial  intelligence and sound    PWC Iot Study Available at  httpswwwstrategyandpwccomgxeninsightsindustry4 0html   Proprietary Data  Preprocessing  Complex models    predictions   Patterns recognition Feature  extraction convolutional  neural networks pre trained  on millions of recordings   traditional vibro diagnostics      Copyright Our company 23  All rights reserved  Confidential  nGuard  nEdge are the magic bullet of PdM  Data driven analysis   The customer objective is to benefit from the accurate estimation of Remaining Useful Lifetime of the  assets  what is going to break and when  Our company excels in application of machine learning  techniques on the most relevant large data sets to solve this objective   High  frequency analysis   Data are continuous time series data  allowing more comprehensive  predictions of failure monitoring broader type of assets including  machines with irregular operations  We sample up to 60x per minute  with up to 192k Hz That is 10000x more data compare to a reading  every hour battery sensors IoT edge computing allows local data  processing   Local data processing   Differentiated hardware offering provides easy to deploy end toend  solution Customers can avoid costly IT projects and easily deploy  sensors Proprietary IoT edge device  can process large volumes of  data on site utilising  our algorithms   Our edge device is updated   secure   TOP AI models   Several comprehensive machine learning models Adding not only the  basic ISO 2018 16 heuristics for rotary equipment but moreover adding  leading AI Assisted monitoring capability  Enable by Deep Learning AI  pretrained on millions of recordings  Classification  996  Unsupervised anomaly detection 89 accuracy in machine failure  prediction   Extensive  data collective   Collecting the most important  relevant data for real time  continuously  machine failure prediction using the full acoustics spectrum vibration   ultrasonic We plan to add Electric current and other sensor capability  Wide range frequency wired sensors No battery to be replaced   Audio signals ultrasonic  vibration provides the  data to identify coming mechanical failure These  are the most useful signals Our company collected  tens fo terrabites  of data across variety of machines  and mechanical components     Current and Thermo  are the next two other useful  signals relevant for PdM are thermography and  intensity of current We are currentlyadding the current  measurements and tested the use of thermal cameras      Other variables are noise  with limited correlation  to PdM The information  from SCADA are good for  the machine operating  context but study done  by Airbus shows a limited  correlation to PdM   Copyright Our company 23  All rights reserved  Confidential  Several level of data processing levels can be deployed   1Loudness detection  automatically track if machines operates  provides the asset utilization Implemented    2Audio clusters detection  the algorithm detects several known  operating modes of machine eg tracking state of process   3Energy level detection ISO 20816   detect the motion above  standard operation limits defined by the norm Implemented     4Machine monitoring by detecting frequency shifts  detect  changes in frequency spectrum and alert them as anomalies vibro  diagnostics for rotary equipment Implemented    5AI based anomaly detection  algorithm is pre trained and  evaluated using 100000 emulated issues to detect coming  mechanical failure We have achieved top performing algorithm   6AI Automation and calibration  Our automated ML Pipeline allows  to setup model by one click training End user eg service  manage set up the monitoring of a machine without development   7Advanced AI with labels  detection of the issues including the  potential cause of the anomaly based on the audio pattern The  current algorithm is in development and testing   8Full sensor fusion  standard AI models for multiple different  sensors infra pressure etc Conducted early trials We are  extending our hardware to be able to collect multiple different  sensoric data starting by detecting current measurements    9Advanced AI with time   algorithm not only detect the issues but  estimates time to failure Remaining Useful Lifetime We are in the  process of data collection     We have developed State of the Art AI Solutions  Product Suite Algorithm   Available now  Plan  Piloting    Copyright Our company 23  All rights reserved  Confidential   Generic Purpose Anomaly  automated calibration    Our AI is trained in three steps   Step 1 Model pre training   We have collected millions of recordings of  different machines sounds and thousands of  failures noises to provide the best possible  accuracy The model is pre trained on large  database of all type of sounds   Embedding space   feature extraction    Step1Very large DB of all type of sounds   Step2 Machine specific sounds   Components  Components   Components  Components   Stream  Stream  Step 3 Stream   Step 2 Machine specific model   Generic purpose AI is trained for each  particular machine type We built the  embedding space extracting the key  character of the sound using machine  specific sounds  real and augmented  failures   per sensor    Nominal sounds   million of samples    Nominal sounds   million of samples    Real and Augmented Failures   100k samples     Step 3 Calibration for each sensor   AI is calibrated for each individual machine using specific data streams of each sensor Anomalies  are detected We apply traditional diagnostics solution for interpretation of rotary equipment   human expertise to further label the data  improve accuracy Our solution provide personalised  health state for each machine    Copyright Our company 23  All rights reserved  Confidential   9  Visualisation of chain issue in transportation component   Soundwave     Spectrogram is a transformed  soundwave into the  mathematically processed form  which is better for pattern  recognition       Data Fingerprints     The audio embedding  space  fingerprints reduces the number  of samples required to recognise  the type of the issue       Anomaly score     The model is trained to recognize  a wide set of issues The  operating model of the machines  can be quite complex Score  above a given threshold triggers a  warning or an alert   Alert Corruption    Alert De serviced  How the technology works   1 Sound wave   Spectrogram   2 Data Fingerprints   3 Anomaly score and alerts   Copyright Our company 23  All rights reserved  Confidential   The AI model learns the nominal sound patterns based on spectrograms from recorded data  visualizing the change of a nonstationary signals frequency content over time   Then it compares every upcoming sample with its memory to determine if some kind of change  occurred in comparison to learned sounds   10  normal  operation  foreign object appeared and  is bouncing between the  comb plate and the steps  foreign object got stuck  under the comb plate and is  grinding the asset without  triggering the safety stop   Alert warning     Machine Escalator OTIS 616 no 123   Component Comb plate   Placement Comb plate right side   Facility Transport company headquarters   Project Escalators monitoring   Company Transport company     Event type Alert   Event time December 13 2022 1535 UTC   Event description Foreign object is stuck under  the comb plate of the escalator and grinding  against the steps   increase in anomaly score  which triggers alerts  Real time monitoring  Alerts notifications and 247 portal access   Copyright Our company 23  All rights reserved  Confidential  11  selected  nominal data  cold starts of the asset drive  system during cold winter  months   The AI model learns from the machine nominal state In case the operational mode changes we  can quickly add the new operation mode into the training dataset     As we see on the yellow curve at the beginning there are a lot of anomalies over the 05  threshold Once we incorporate the feedback from the customer and label it as nominal data of  cold start of the machine the AI model adopts and does not alert such a state any more  093  Můstek station   Training and Development of the Model  A few days of operation is used as nominal data   Copyright Our company 23  All rights reserved  Confidential   12  Algorithm accuracy improves throughout the time   We can detect extensive number number of issues immediately after  installation The accuracy increased through time We are evaluating the  accuracy of the models on our Test Framework It uses hundreds of hours  of broken machines in tens of tasksdatasets  We have developed  tools to  provide effective learning feedback for AI Our diagnostic experts are  helping with the interpretation of the data collection well labeled all  alerts     Days before issue  recognition  CHP Ver 12   31 defect in total  CHP Ver 20   64 defects in  total  DCASE Ver   100 defects   1 day  45  59 89   2 days  42  55   3 days  38  53   47 days  35 51  3 MODEL   UPDATE  4 MODEL UPDATE   DEPLOYMENT  5 COLLECT   OPERATION   FEEDBACK  1 INITIAL   MODEL   2 COLLECT   OPERATION   FEEDBACK  6 MODEL   UPDATE  7 MODEL UPDATE   DEPLOYMENT  8 COLLECT   OPERATION   FEEDBACK  Interactive development    improving every week    System improves through its use   Copyright Our company 23  All rights reserved  Confidential   Thank you   The New Standard in Machine Data Analysis   360 View of Your Assets in Action   '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_pdf_data = clean_text(data_1_pdf_data)\n",
    "data_1_pdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TE-mFYhpkDQK",
   "metadata": {
    "id": "TE-mFYhpkDQK"
   },
   "outputs": [],
   "source": [
    "data_2_pdf_data = clean_text(data_2_pdf_data)\n",
    "data_2_pdf_2_data = clean_text(data_2_pdf_2_data)\n",
    "data_2_pdf_3_data = clean_text(data_2_pdf_3_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ydCEdf_xYgm8",
   "metadata": {
    "id": "ydCEdf_xYgm8"
   },
   "source": [
    "Docs: Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bo7hyEmEkV7Q",
   "metadata": {
    "id": "bo7hyEmEkV7Q"
   },
   "outputs": [],
   "source": [
    "data_2_doc_1_data = clean_text(data_2_doc_1_data)\n",
    "data_2_doc_2_data = clean_text(data_2_doc_2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KFzxpucTCriO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "KFzxpucTCriO",
    "outputId": "ea380ad8-23a8-493f-bf54-13b0540d86e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'         Procedure Security Incidents   \\t Introduction This document describes how The Company defines security incidents and how these incidents are being handled What is a security incident A security incident occurs when an event occurs where there is the possibility that the confidentiality integrity or availability of information or informationprocessing systems is or could be endangered Some examples of security incidents are viruses andor malware infections or attempts to gain unauthorized access to information or systems What is a data breach A security incident can concern a data breach There is a data breach if there is an infringement on the protection of personal data Not only the release or leakage of personal data results in a data breach but also when unlawful data is processed Reporting a security incident Every employee of The Company is authorized to report a security incident This is done by the companys Teams channel security which is monitored by the Security Officer It is important that the person reporting a security incident provides as much evidence as possible for example a screen print or photo Next to that it is also possible to report incidents to the security officer via email  Assessing a security incident For every reported security incident the Security Officer primarily assesses whether there is a data breach A data breach must be submitted within 72 hours via the website of the Dutch Data Protection Authority If it is likely that the data breach will also result in unfavorable consequences for the privacy of the data subject then this must also be informed A notification to the person concerned is not necessary if measures have been taken in accordance with the AVG and these have been applied to the personal data concerned Handling of a security incident The handling of a security incident is the responsibility of the Security Officer whereby tasks can be delegated Relevant parties or business units can be involved in handling a security incident An integral part of the handling is the execution and documentation of a cause analysis Finding the cause enables The Company to act in a targeted manner and learn from the security incidents that have occurred'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2_doc_2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b796dc-f69d-4686-b802-bd0d8f679ee8",
   "metadata": {
    "id": "c2b796dc-f69d-4686-b802-bd0d8f679ee8"
   },
   "source": [
    "### Analysis 1: Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xvdXHuBMB-Au",
   "metadata": {
    "id": "xvdXHuBMB-Au"
   },
   "source": [
    "Data sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b453f-1bc2-4cad-8021-e548d307f154",
   "metadata": {
    "id": "c33b453f-1bc2-4cad-8021-e548d307f154"
   },
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"Counts the number of words in the provided text.\"\"\"\n",
    "    words = text.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gzn4gz8dNEdy",
   "metadata": {
    "id": "gzn4gz8dNEdy"
   },
   "outputs": [],
   "source": [
    "#Adjusting text in the dataframe column\n",
    "data_1_excel_combined_text = ' '.join(data_1_excel_data.iloc[:, 0].astype(str))\n",
    "data_2_excel_combined_text = ' '.join(data_2_excel_data.iloc[:, 0].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SS0sZy3wQJrl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS0sZy3wQJrl",
    "outputId": "cde624af-252c-4cf6-9d00-2035db6ea24f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4386\n"
     ]
    }
   ],
   "source": [
    "#Word count in first data sample\n",
    "cw_1_1 = count_words(data_1_pdf_data)\n",
    "cw_1_2 = count_words(data_1_excel_combined_text)\n",
    "print(cw_1_1 + cw_1_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aKMz0QI7QJy2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKMz0QI7QJy2",
    "outputId": "f06d4279-79a4-43e9-9c83-a45f38fa0278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6638\n"
     ]
    }
   ],
   "source": [
    "#Word count in second data sample\n",
    "cw_2_1 = count_words(data_2_pdf_data)\n",
    "cw_2_2 = count_words(data_2_pdf_2_data)\n",
    "cw_2_3 = count_words(data_2_pdf_3_data)\n",
    "cw_2_4 = count_words(data_2_excel_combined_text)\n",
    "cw_2_5 = count_words(data_2_doc_1_data)\n",
    "cw_2_6 = count_words(data_2_doc_2_data)\n",
    "print(cw_2_1 + cw_2_2 + cw_2_3 + cw_2_4 + cw_2_5 + cw_2_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273bea3-ecaa-4fac-83d0-5fe547b7873d",
   "metadata": {
    "id": "f273bea3-ecaa-4fac-83d0-5fe547b7873d"
   },
   "source": [
    "### Analysis 2: Word Frequency (10 most frequent words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckA4-2oKUVeI",
   "metadata": {
    "id": "ckA4-2oKUVeI"
   },
   "outputs": [],
   "source": [
    "def top_10_frequent_words(text, remove_stopwords=False):\n",
    "    # Remove punctuation and convert text to lowercase\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    if remove_stopwords:\n",
    "        # Remove stop words\n",
    "        sw = set(stopwords.words('english'))\n",
    "        filtered_words = [word for word in words if word not in sw]\n",
    "        word_counts = Counter(filtered_words)\n",
    "\n",
    "    # Return the 10 most common words\n",
    "    return word_counts.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jvoAFsHHSIGN",
   "metadata": {
    "id": "jvoAFsHHSIGN"
   },
   "source": [
    "10 most frequent words in Data sample 1 before and after stop words are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60074a1b-1ae5-46e8-971f-100199861c9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60074a1b-1ae5-46e8-971f-100199861c9c",
    "outputId": "07234035-bdf3-4468-fd99-d470f8ec6deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 216), ('of', 147), ('and', 106), ('our', 88), ('to', 88), ('a', 76), ('is', 60), ('in', 60), ('for', 58), ('we', 57)]\n",
      "[('data', 54), ('machine', 43), ('model', 35), ('company', 26), ('ai', 26), ('maintenance', 23), ('training', 21), ('system', 20), ('models', 17), ('process', 16)]\n"
     ]
    }
   ],
   "source": [
    "joint_text_1 = ' '.join([data_1_pdf_data,data_1_excel_combined_text ])\n",
    "print(top_10_frequent_words(joint_text_1, remove_stopwords=False))\n",
    "print(top_10_frequent_words(joint_text_1, remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4uabaThUj1L",
   "metadata": {
    "id": "s4uabaThUj1L"
   },
   "source": [
    "10 most frequent words in Data sample 2 before and after stop words are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "keRW3HlwUsI5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keRW3HlwUsI5",
    "outputId": "474767c1-5f04-4b21-8965-19cd49ffa7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 340), ('to', 179), ('and', 158), ('of', 143), ('is', 136), ('our', 117), ('a', 110), ('in', 100), ('for', 100), ('we', 92)]\n",
      "[('data', 48), ('models', 47), ('product', 41), ('new', 38), ('detection', 33), ('company', 32), ('per', 31), ('security', 27), ('streams', 25), ('model', 22)]\n"
     ]
    }
   ],
   "source": [
    "joint_text_2 = ' '.join([data_2_pdf_data, data_2_pdf_2_data, data_2_pdf_3_data, data_2_excel_combined_text, data_2_doc_1_data,  data_2_doc_2_data ])\n",
    "print(top_10_frequent_words(joint_text_2, remove_stopwords=False))\n",
    "print(top_10_frequent_words(joint_text_2, remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fS3R4ciYl7z_",
   "metadata": {
    "id": "fS3R4ciYl7z_"
   },
   "source": [
    "### Analysis 3: Cosine Similarity of text and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3n5baB0iW-PI",
   "metadata": {
    "id": "3n5baB0iW-PI"
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(text, list_of_dimensions):\n",
    "    # Combine the list items and the text into a single list\n",
    "    documents = list_of_dimensions + [text]\n",
    "\n",
    "    # Vectorize the documents\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "\n",
    "    # Flatten to a 1D array and return\n",
    "    return cosine_similarities.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yVhWA0GWrbH_",
   "metadata": {
    "id": "yVhWA0GWrbH_"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove the stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y7FFoRLKmLI-",
   "metadata": {
    "id": "y7FFoRLKmLI-"
   },
   "outputs": [],
   "source": [
    "list_of_dimensions = ['Dataset size & quality', 'AI product roadmap', 'AI & data strategy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hFIAtKBvZksd",
   "metadata": {
    "id": "hFIAtKBvZksd"
   },
   "source": [
    "Data sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IUlkUiDSZk-Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUlkUiDSZk-Z",
    "outputId": "9f86a756-5770-40d6-cff2-4b1fa9381557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01349922 0.02475472 0.09397015]\n"
     ]
    }
   ],
   "source": [
    "print(calculate_cosine_similarity(joint_text_1, list_of_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t0XxcaECrfwE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0XxcaECrfwE",
    "outputId": "aa1f2aa9-5f74-4931-aa2e-f5327a54828a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03700716 0.06786334 0.25761256]\n"
     ]
    }
   ],
   "source": [
    "print(calculate_cosine_similarity(remove_stop_words(joint_text_1), list_of_dimensions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KPDQttkGZlG_",
   "metadata": {
    "id": "KPDQttkGZlG_"
   },
   "source": [
    "Data sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-60_L4PKZlNe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-60_L4PKZlNe",
    "outputId": "d67a8f17-1239-4da7-ff36-a5a291719fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01238437 0.05125239 0.05558784]\n"
     ]
    }
   ],
   "source": [
    "print(calculate_cosine_similarity(joint_text_2, list_of_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GrXmyM9crgN_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrXmyM9crgN_",
    "outputId": "f5d2186d-c1f8-4412-e976-91fd73f9bd21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04013975 0.16611739 0.18016927]\n"
     ]
    }
   ],
   "source": [
    "print(calculate_cosine_similarity(remove_stop_words(joint_text_2), list_of_dimensions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wx1x0p9HmLab",
   "metadata": {
    "id": "Wx1x0p9HmLab"
   },
   "source": [
    "### Analysis 4: Number of AI start-ups in Y Combinator Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C7w8L6sclO88",
   "metadata": {
    "id": "C7w8L6sclO88"
   },
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "ycd = pd.read_csv(ycd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U0VU2gpFlGOX",
   "metadata": {
    "id": "U0VU2gpFlGOX"
   },
   "outputs": [],
   "source": [
    "#Change column from string to list of strings\n",
    "ycd['tags'] = ycd['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "snOFF0RDkvJ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snOFF0RDkvJ0",
    "outputId": "9786d359-0213-4403-f26e-10928e763f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      company_id   company_name  \\\n",
      "2          28409        BerriAI   \n",
      "9          28367      Atri Labs   \n",
      "22         28183          Metal   \n",
      "44         28114      BabylonAI   \n",
      "49         28089         Thread   \n",
      "...          ...            ...   \n",
      "7930         511     Semantics3   \n",
      "8033         391    Canopy Labs   \n",
      "8112         105     LeadGenius   \n",
      "8273         245  Directed Edge   \n",
      "8311         289    JustSpotted   \n",
      "\n",
      "                                      short_description  \\\n",
      "2                Stop OpenAI Errors w/ 1 line of code 👈   \n",
      "9       Open-source web framework for Python developers   \n",
      "22             Machine learning embeddings as a service   \n",
      "44         Datadog for machine learning on edge devices   \n",
      "49     Incident Management platform for large enterp...   \n",
      "...                                                 ...   \n",
      "7930  Data and AI platform for Ecommerce & Cross-Bor...   \n",
      "8033  Canopy Labs automates customer analytics for s...   \n",
      "8112  LeadGenius is an account-based marketing and l...   \n",
      "8273                           Product recommendations.   \n",
      "8311                         Acquired by Google in 2011   \n",
      "\n",
      "                                       long_description batch    status  \\\n",
      "2     Stop OpenAI Errors in 1 line of code\\r\\n\\r\\n``...   W23    Active   \n",
      "9     Atri Labs is Vercel for Python developers. \\r\\...   W23    Active   \n",
      "22    Metal does machine learning embeddings as a se...   W23    Active   \n",
      "44    BabylonAI (YC W23) is a smart logging SDK for ...   W23    Active   \n",
      "49    Thread is an incident management tool for larg...   W23    Active   \n",
      "...                                                 ...   ...       ...   \n",
      "7930  Our products:\\r\\n- Data APIs/Feeds (Retail fee...   W13  Acquired   \n",
      "8033  Every customer reaches a buying decision in th...   S12  Inactive   \n",
      "8112  LeadGenius is the most efficient way to equip ...   S11    Active   \n",
      "8273  Directed Edge delivers Amazon-like \"People who...   S09    Active   \n",
      "8311  The artist-formerly-known-as Scoopler is a rea...   S08  Acquired   \n",
      "\n",
      "                                                   tags             location  \\\n",
      "2     [Artificial Intelligence, Developer Tools, Gen...        San Francisco   \n",
      "9     [Artificial Intelligence, Developer Tools, Ope...        San Francisco   \n",
      "22    [Artificial Intelligence, Machine Learning, B2...             New York   \n",
      "44    [Artificial Intelligence, Developer Tools, Mac...        San Francisco   \n",
      "49    [Artificial Intelligence, Developer Tools, B2B...        San Francisco   \n",
      "...                                                 ...                  ...   \n",
      "7930   [Artificial Intelligence, Logistics, E-commerce]        San Francisco   \n",
      "8033  [Artificial Intelligence, Analytics, Marketing...             New York   \n",
      "8112   [Artificial Intelligence, B2B, Sales, Marketing]         Berkeley, CA   \n",
      "8273  [Artificial Intelligence, Machine Learning, Re...        San Francisco   \n",
      "8311                      [Artificial Intelligence, ML]  Copenhagen, Denmark   \n",
      "\n",
      "     country  year_founded  num_founders  \\\n",
      "2         US        2023.0             2   \n",
      "9         US        2022.0             2   \n",
      "22        US        2023.0             3   \n",
      "44        US        2023.0             2   \n",
      "49        US        2023.0             3   \n",
      "...      ...           ...           ...   \n",
      "7930      US        2012.0             2   \n",
      "8033      US           NaN             2   \n",
      "8112      US           NaN             1   \n",
      "8273      US           NaN             1   \n",
      "8311      DK           NaN             1   \n",
      "\n",
      "                                         founders_names  team_size  \\\n",
      "2                  ['Krrish Dholakia', 'Ishaan Jaffer']        2.0   \n",
      "9              ['Darshita Chaturvedi', 'Shyam Swaroop']        2.0   \n",
      "22     ['Taylor Lowe', \"James O'Dwyer\", 'Sergio Prada']        3.0   \n",
      "44                  ['Rangel Milushev', 'Ahmad Roumie']        2.0   \n",
      "49    ['Yuheng Wang', 'Harsha Vankayalapati', 'Akeem...        3.0   \n",
      "...                                                 ...        ...   \n",
      "7930                  ['Sivamani Varun', 'Vinoth Gopi']       25.0   \n",
      "8033                ['Wojciech Gryc', 'Jorge Escobedo']       11.0   \n",
      "8112                                  ['Prayag Narula']       50.0   \n",
      "8273                                  ['Scott Wheeler']        2.0   \n",
      "8311                                     ['Dilan Dane']        2.0   \n",
      "\n",
      "                        website  \\\n",
      "2             https://berri.ai/   \n",
      "9          https://atrilabs.com   \n",
      "22         https://getmetal.io/   \n",
      "44        https://babylonai.dev   \n",
      "49      http://www.usethread.io   \n",
      "...                         ...   \n",
      "7930  http://www.semantics3.com   \n",
      "8033      http://canopylabs.com   \n",
      "8112      http://leadgenius.com   \n",
      "8273    http://directededge.com   \n",
      "8311     http://justspotted.com   \n",
      "\n",
      "                                                 cb_url  \\\n",
      "2                                                   NaN   \n",
      "9                                                   NaN   \n",
      "22                                                  NaN   \n",
      "44                                                  NaN   \n",
      "49    https://www.crunchbase.com/organization/thread...   \n",
      "...                                                 ...   \n",
      "7930  https://www.crunchbase.com/organization/semant...   \n",
      "8033  https://www.crunchbase.com/organization/canopy...   \n",
      "8112  https://www.crunchbase.com/organization/mobile...   \n",
      "8273  https://www.crunchbase.com/organization/direct...   \n",
      "8311  https://www.crunchbase.com/organization/justsp...   \n",
      "\n",
      "                                           linkedin_url  \n",
      "2            https://www.linkedin.com/company/berri-ai/  \n",
      "9           https://www.linkedin.com/company/atri-labs/  \n",
      "22     https://www.linkedin.com/company/getmetal/about/  \n",
      "44          https://www.linkedin.com/company/babylonai/  \n",
      "49    https://www.linkedin.com/company/thread-incorp...  \n",
      "...                                                 ...  \n",
      "7930                                                NaN  \n",
      "8033                                                NaN  \n",
      "8112                                                NaN  \n",
      "8273                                                NaN  \n",
      "8311                                                NaN  \n",
      "\n",
      "[599 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "#Collecting AI companies\n",
    "ai_companies = ycd[ycd['tags'].apply(lambda tags: 'Artificial Intelligence' in tags if isinstance(tags, list) else False)]\n",
    "print(ai_companies)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4bc7a400e35f160b13ed52195005e41b219907c1be09b125a1c17e685484faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
